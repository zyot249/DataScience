{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3ZZlOnp2i84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "00d60abd-5f0b-4d0a-d683-8eb9b4b3455e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuPSC43C3zF8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "e8b28176-e46a-4c70-dc61-d6d07d31528f"
      },
      "source": [
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/1-training-data.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/20163727-test.csv', names=['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'y'])\n",
        "test.info()"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15 entries, 0 to 14\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   A1      15 non-null     float64\n",
            " 1   A2      15 non-null     float64\n",
            " 2   A3      15 non-null     int64  \n",
            " 3   A4      15 non-null     float64\n",
            " 4   A5      15 non-null     int64  \n",
            " 5   A6      15 non-null     float64\n",
            " 6   A7      15 non-null     int64  \n",
            " 7   A8      15 non-null     int64  \n",
            " 8   y       15 non-null     int64  \n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 1.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CNZ9oku9CGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.replace('?', np.nan, inplace=True)\n",
        "from sklearn.impute import SimpleImputer\n",
        "train['A1'] = pd.to_numeric(train['A1'], errors='coerce')\n",
        "train['A2'] = pd.to_numeric(train['A2'], errors='coerce')\n",
        "train['A3'] = pd.to_numeric(train['A3'], errors='coerce')\n",
        "train['A4'] = pd.to_numeric(train['A4'], errors='coerce')\n",
        "train['A5'] = pd.to_numeric(train['A5'], errors='coerce')\n",
        "train['A6'] = pd.to_numeric(train['A6'], errors='coerce')\n",
        "train['A7'] = pd.to_numeric(train['A7'], errors='coerce')\n",
        "train['A8'] = pd.to_numeric(train['A8'], errors='coerce')\n",
        "\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
        "train = pd.DataFrame(data=imp.fit_transform(train), columns=['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'y'] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3VjCp-cS4SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train.drop('y', axis=1)\n",
        "y = train['y']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUI3-at7xS-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "799a8278-8cb6-434b-93bb-5e04dce09640"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "\n",
        "f1 = make_scorer(f1_score , average='macro')\n",
        "\n",
        "n_estimators = [800, 1200, 1500]\n",
        "max_depth = [15, 25, 30]\n",
        "min_samples_split = [2, 5, 10, 15, 100]\n",
        "min_samples_leaf = [1, 2, 5, 10] \n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
        "              min_samples_split = min_samples_split, \n",
        "             min_samples_leaf = min_samples_leaf)\n",
        "\n",
        "gridF = GridSearchCV(RandomForestClassifier(), hyperF, cv = 3, verbose = 1, \n",
        "                      n_jobs = -1,\n",
        "                      scoring=f1)\n",
        "bestF = gridF.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 180 candidates, totalling 540 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:  5.3min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOVZuezI8aul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestF.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BllchcGMA5xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, average_precision_score\n",
        "model = RandomForestClassifier(n_estimators=1200,\n",
        "                               bootstrap=False,\n",
        "                               criterion='entropy',\n",
        "                               max_depth=15,\n",
        "                                min_samples_split=2,\n",
        "                                min_samples_leaf=1,\n",
        "                                random_state=42,\n",
        "                                n_jobs=-1, class_weight='balanced_subsample')\n",
        "                               \n",
        "model.fit(X_train, y_train)\n",
        "predicted = model.predict(X_test)\n",
        "print(classification_report(y_test, predicted))\n",
        "print(accuracy_score(y_test, predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m8gEMo6C3Jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "mm_scaler = preprocessing.StandardScaler()\n",
        "X_train_scaled = mm_scaler.fit_transform(X_train)\n",
        "X_test_scaled = mm_scaler.fit_transform(X_test)\n",
        "\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(X_train_scaled, y_train)\n",
        "predicted = clf.predict(X_test_scaled)\n",
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}